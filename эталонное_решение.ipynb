{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Разбор решения хакатона\n",
        "## Дообучение SAM2"
      ],
      "metadata": {
        "id": "5YGo3HuUYLml"
      },
      "id": "5YGo3HuUYLml"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/segment-anything-2\n",
        "%cd /content/segment-anything-2\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "id": "bBXDKydl1WbK"
      },
      "id": "bBXDKydl1WbK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O sam2_hiera_tiny.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\"\n",
        "!wget -O sam2_hiera_small.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt\"\n",
        "!wget -O sam2_hiera_base_plus.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\"\n",
        "!wget -O sam2_hiera_large.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\""
      ],
      "metadata": {
        "id": "HXBWxbU-1MG2"
      },
      "id": "HXBWxbU-1MG2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/segment-anything-2"
      ],
      "metadata": {
        "id": "EVhGFwM558Eg"
      },
      "id": "EVhGFwM558Eg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/edd91118/train1.zip\n",
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/e5a98368/train2.zip\n",
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/a95eacf7/train3.zip\n",
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/a9a3642d/train4.zip\n",
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/adacb253/val.zip\n",
        "!wget https://storage.yandexcloud.net/ds-ods/files/files/b5ac09fa/annotations.zip"
      ],
      "metadata": {
        "id": "W7I1From5DSW"
      },
      "id": "W7I1From5DSW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train1.zip\n",
        "!unzip train2.zip\n",
        "!unzip train3.zip\n",
        "!unzip train4.zip\n",
        "!unzip val.zip\n",
        "!unzip annotations.zip"
      ],
      "metadata": {
        "id": "hw0Abfjr6MI9"
      },
      "id": "hw0Abfjr6MI9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train"
      ],
      "metadata": {
        "id": "dJVYjLxSuLDh"
      },
      "id": "dJVYjLxSuLDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "train_path = \"train\"\n",
        "for folder_name in [\"train1\", \"train2\", \"train3\", \"train4\"]:\n",
        "  for file_name in os.listdir(folder_name):\n",
        "    src = os.path.join(folder_name, file_name)\n",
        "    shutil.move(src, train_path)"
      ],
      "metadata": {
        "id": "9qXwGc5StXKO"
      },
      "id": "9qXwGc5StXKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "import json\n",
        "\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "with open(\"val_annotations.json\", \"r\") as f:\n",
        "  val_data = json.load(f)\n",
        "\n",
        "with open(\"train_annotations.json\", \"r\") as f:\n",
        "  train_data = json.load(f)"
      ],
      "metadata": {
        "id": "wrjtmKQy2UTo"
      },
      "id": "wrjtmKQy2UTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools import _mask"
      ],
      "metadata": {
        "id": "IpOETYsqjHjb"
      },
      "id": "IpOETYsqjHjb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['images'][0]"
      ],
      "metadata": {
        "id": "oVekBOBxhdT2"
      },
      "id": "oVekBOBxhdT2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зафиксировать seed для воспроизведения обучения."
      ],
      "metadata": {
        "id": "omOIQPD5f-Cj"
      },
      "id": "omOIQPD5f-Cj"
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds():\n",
        "    SEED_VALUE = 42\n",
        "    random.seed(SEED_VALUE)\n",
        "    np.random.seed(SEED_VALUE)\n",
        "    torch.manual_seed(SEED_VALUE)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(SEED_VALUE)\n",
        "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seeds()"
      ],
      "metadata": {
        "id": "69wovLIXf8hd"
      },
      "id": "69wovLIXf8hd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Считывание данных для обучения"
      ],
      "metadata": {
        "id": "G5VJmXyr_Dij"
      },
      "id": "G5VJmXyr_Dij"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def read_batch(data, data_path):\n",
        "   # Select a random entry\n",
        "  ent = data['annotations'][np.random.randint(len(data['annotations']))]\n",
        "\n",
        "  ind = 0\n",
        "  while data['images'][ind]['id'] != ent['image_id']:\n",
        "    ind += 1\n",
        "  image_path = data['images'][ind]['file_name']\n",
        "  image_path = os.path.join(data_path, image_path)\n",
        "  Img = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
        "  binary_mask = np.zeros((693, 1344), dtype=np.uint8)\n",
        "  for pts in ent['segmentation']:\n",
        "    # Шаг 1: Разделить на пары (x, y)\n",
        "    points = [[pts[i], pts[i + 1]] for i in range(0, len(pts), 2)]\n",
        "\n",
        "    # Шаг 2: Обернуть в список (даже если один полигон)\n",
        "    polygon = [points]\n",
        "\n",
        "    # Шаг 3: Преобразовать в NumPy массив с типом int32\n",
        "    pts_array = np.array(polygon, dtype=np.int32)\n",
        "    cv2.fillPoly(binary_mask, pts_array , color=1)\n",
        "\n",
        "  # Erode the combined binary mask to avoid boundary points\n",
        "  eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n",
        "\n",
        "  points = []\n",
        "  # Get all coordinates inside the eroded mask and choose random points\n",
        "  coords = np.argwhere(eroded_mask > 0)\n",
        "  if len(coords) > 0:\n",
        "      yx = coords[np.random.randint(len(coords))]  # Randomly select a point\n",
        "      points.append([yx[1], yx[0]])  # Append in [x, y] format (col, row)\n",
        "\n",
        "  points = np.array(points)\n",
        "  binary_mask = np.expand_dims(binary_mask, axis=-1)  # Now shape is (1024, 1024, 1)\n",
        "  binary_mask = binary_mask.transpose((2, 0, 1))\n",
        "  points = np.expand_dims(points, axis=1)\n",
        "\n",
        "  # Return the image, binarized mask, points, and number of masks\n",
        "  return Img, binary_mask, points, 1"
      ],
      "metadata": {
        "id": "8-uzLhZ09zv3"
      },
      "id": "8-uzLhZ09zv3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка кода для обучения"
      ],
      "metadata": {
        "id": "iZTfmgEy_MRB"
      },
      "id": "iZTfmgEy_MRB"
    },
    {
      "cell_type": "code",
      "source": [
        "sam2_checkpoint = \"sam2_hiera_small.pt\"  # @param [\"sam2_hiera_tiny.pt\", \"sam2_hiera_small.pt\", \"sam2_hiera_base_plus.pt\", \"sam2_hiera_large.pt\"]\n",
        "model_cfg = \"sam2_hiera_s.yaml\" # @param [\"sam2_hiera_t.yaml\", \"sam2_hiera_s.yaml\", \"sam2_hiera_b+.yaml\", \"sam2_hiera_l.yaml\"]\n",
        "\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "predictor = SAM2ImagePredictor(sam2_model)"
      ],
      "metadata": {
        "id": "XfJGlvX5_Jzf"
      },
      "id": "XfJGlvX5_Jzf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train mask decoder.\n",
        "predictor.model.sam_mask_decoder.train(True)\n",
        "\n",
        "# Train prompt encoder.\n",
        "predictor.model.sam_prompt_encoder.train(True)\n",
        "\n",
        "# Configure optimizer.\n",
        "optimizer=torch.optim.AdamW(params=predictor.model.parameters(),lr=0.0001,weight_decay=1e-4) #1e-5, weight_decay = 4e-5\n",
        "\n",
        "# Mix precision.\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# No. of steps to train the model.\n",
        "NO_OF_STEPS = 3000 # @param\n",
        "\n",
        "# Fine-tuned model name.\n",
        "FINE_TUNED_MODEL_NAME = \"fine_tuned_sam2\""
      ],
      "metadata": {
        "id": "kDWhQX74_y8K"
      },
      "id": "kDWhQX74_y8K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "I4Xm2AhO3ZHy"
      },
      "id": "I4Xm2AhO3ZHy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.2) # 500 , 250, gamma = 0.1\n",
        "accumulation_steps = 4  # Number of steps to accumulate gradients before updating\n",
        "\n",
        "for step in range(1, NO_OF_STEPS + 1):\n",
        "   with torch.cuda.amp.autocast():\n",
        "       image, mask, input_point, num_masks = read_batch(train_data, 'train')\n",
        "       if image is None or mask is None or num_masks == 0:\n",
        "           continue\n",
        "\n",
        "       input_label = np.ones((num_masks, 1))\n",
        "       if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
        "           continue\n",
        "\n",
        "       if input_point.size == 0 or input_label.size == 0:\n",
        "           continue\n",
        "       image = image.copy()\n",
        "       predictor.set_image(image)\n",
        "       mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(input_point, input_label, box=None, mask_logits=None, normalize_coords=True)\n",
        "       if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
        "           continue\n",
        "\n",
        "       sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "           points=(unnorm_coords, labels), boxes=None, masks=None,\n",
        "       )\n",
        "\n",
        "       batched_mode = unnorm_coords.shape[0] > 1\n",
        "       high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "       low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "           image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
        "           image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "           sparse_prompt_embeddings=sparse_embeddings,\n",
        "           dense_prompt_embeddings=dense_embeddings,\n",
        "           multimask_output=True,\n",
        "           repeat_image=batched_mode,\n",
        "           high_res_features=high_res_features,\n",
        "       )\n",
        "       prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "\n",
        "       gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "       prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "       seg_loss = (-gt_mask * torch.log(prd_mask + 0.000001) - (1 - gt_mask) * torch.log((1 - prd_mask) + 0.00001)).mean()\n",
        "\n",
        "       inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
        "       iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
        "       score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "       loss = seg_loss + score_loss * 0.05\n",
        "\n",
        "       # Apply gradient accumulation\n",
        "       loss = loss / accumulation_steps\n",
        "       scaler.scale(loss).backward()\n",
        "\n",
        "       # Clip gradients\n",
        "       torch.nn.utils.clip_grad_norm_(predictor.model.parameters(), max_norm=1.0)\n",
        "\n",
        "       if step % accumulation_steps == 0:\n",
        "           scaler.step(optimizer)\n",
        "           scaler.update()\n",
        "           predictor.model.zero_grad()\n",
        "\n",
        "       # Update scheduler\n",
        "       scheduler.step()\n",
        "\n",
        "       if step % 500 == 0:\n",
        "           FINE_TUNED_MODEL = FINE_TUNED_MODEL_NAME + \"_\" + str(step) + \".torch\"\n",
        "           torch.save(predictor.model.state_dict(), FINE_TUNED_MODEL)\n",
        "\n",
        "       if step == 1:\n",
        "           mean_iou = 0\n",
        "\n",
        "       mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n",
        "\n",
        "       if step % 100 == 0:\n",
        "           print(\"Step \" + str(step) + \":\\t\", \"Accuracy (IoU) = \", mean_iou)"
      ],
      "metadata": {
        "id": "tNtZpNXn_1FK"
      },
      "id": "tNtZpNXn_1FK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка необходимых библиотек для инференса Megadetecter"
      ],
      "metadata": {
        "id": "75Sd-IMuydEc"
      },
      "id": "75Sd-IMuydEc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q21pbO9z71ma",
      "metadata": {
        "id": "Q21pbO9z71ma"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8 python3.8-dev python3.8-distutils libpython3.8-dev\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "#Check that it points at the right location\n",
        "!python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JwuSn1x28Ser",
      "metadata": {
        "id": "JwuSn1x28Ser"
      },
      "outputs": [],
      "source": [
        "# install pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "\n",
        "#install colab's dependencies\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7HZZCGqA8ZMe",
      "metadata": {
        "id": "7HZZCGqA8ZMe"
      },
      "outputs": [],
      "source": [
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.10/dist-packages/google \\\n",
        "       /usr/local/lib/python3.8/dist-packages/google\n",
        "\n",
        "!sed -i \"s/from IPython.utils import traitlets as _traitlets/import traitlets as _traitlets/\" /usr/local/lib/python3.8/dist-packages/google/colab/*.py\n",
        "!sed -i \"s/from IPython.utils import traitlets/import traitlets/\" /usr/local/lib/python3.8/dist-packages/google/colab/*.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LdcriN_jp6B4",
      "metadata": {
        "id": "LdcriN_jp6B4"
      },
      "outputs": [],
      "source": [
        "#Install PytorchWildlife\n",
        "!pip install pytorchwildlife"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44e7713",
      "metadata": {
        "id": "c44e7713"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from PytorchWildlife.models import detection as pw_detection\n",
        "from PytorchWildlife import utils as pw_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f622040",
      "metadata": {
        "id": "8f622040"
      },
      "outputs": [],
      "source": [
        "# Setting the device to use for computations ('cuda' indicates GPU)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if DEVICE == \"cuda\":\n",
        "    torch.cuda.set_device(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abd07b5",
      "metadata": {
        "id": "6abd07b5"
      },
      "source": [
        "## Инициализация Megadetecter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb25db43",
      "metadata": {
        "id": "eb25db43"
      },
      "outputs": [],
      "source": [
        "detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=\"MDV6-yolov10-e\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://storage.yandexcloud.net/ds-ods/files/files/2ad601fd/test.zip\n",
        "! unzip test.zip"
      ],
      "metadata": {
        "id": "HFstAbSFx3Og"
      },
      "id": "HFstAbSFx3Og",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "561eff0c",
      "metadata": {
        "id": "561eff0c"
      },
      "outputs": [],
      "source": [
        "tgt_folder_path = \"test\"\n",
        "results_md = detection_model.batch_image_detection(tgt_folder_path, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_md[0]"
      ],
      "metadata": {
        "id": "57sYZ_1jvuIP"
      },
      "id": "57sYZ_1jvuIP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools import mask as coco_mask\n",
        "def masks_to_rle(binary_mask):\n",
        "    \"\"\"\n",
        "    Convert binary_mask to COCO RLE format.\n",
        "\n",
        "    Args:\n",
        "        binary_mask.\n",
        "\n",
        "    Returns:\n",
        "        list: List of RLE-encoded masks.\n",
        "    \"\"\"\n",
        "    binary_mask = binary_mask.astype(np.uint8)\n",
        "\n",
        "    # Encode mask using COCO RLE format\n",
        "    rle = coco_mask.encode(np.asfortranarray(binary_mask))\n",
        "\n",
        "    print(rle)\n",
        "    # Ensure COCO compliance\n",
        "    rle['counts'] = rle['counts']\n",
        "\n",
        "\n",
        "    return rle"
      ],
      "metadata": {
        "id": "oeX0CZJla-qp"
      },
      "id": "oeX0CZJla-qp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_md[0]['detections']"
      ],
      "metadata": {
        "id": "GjYl6Z_IEa4i"
      },
      "id": "GjYl6Z_IEa4i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
        "\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "FINE_TUNED_MODEL_WEIGHTS = \"/content/segment-anything-2/fine_tuned_sam2_3000.torch\"\n",
        "predictor.model.load_state_dict(torch.load(FINE_TUNED_MODEL_WEIGHTS))\n",
        "\n",
        "image_path = results_md[0]['img_id']\n",
        "Img = cv2.imread(image_path)[..., ::-1]\n",
        "\n",
        "with torch.no_grad():\n",
        "   image = Img.copy()\n",
        "   predictor.set_image(image)\n",
        "   cx = (results_md[0]['detections'].xyxy[0][0] + results_md[0]['detections'].xyxy[0][2])/2\n",
        "   cy = (results_md[0]['detections'].xyxy[0][1] + results_md[0]['detections'].xyxy[0][3])/2\n",
        "   input_points = np.array([[cx, cy]])\n",
        "   masks, scores, logits = predictor.predict(\n",
        "       point_coords=[input_points],\n",
        "       point_labels=np.ones([input_points.shape[0], 1])\n",
        "   )"
      ],
      "metadata": {
        "id": "9QqvZ9ik9hgZ"
      },
      "id": "9QqvZ9ik9hgZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "predictions = []\n",
        "for result in results_md:\n",
        "  if len(result['normalized_coords']) != 0:\n",
        "    image_path = result['img_id']\n",
        "    Img = cv2.imread(image_path)[..., ::-1]\n",
        "    # Perform inference and predict masks\n",
        "    with torch.no_grad():\n",
        "      image = Img.copy()\n",
        "      predictor.set_image(image)\n",
        "      for detection in result['detections'].xyxy:\n",
        "        cx = (detection[0] + detection[2])/2\n",
        "        cy = (detection[1] + detection[3])/2\n",
        "        input_points = np.array([[cx, cy]])\n",
        "        masks, scores, logits = predictor.predict(\n",
        "            point_coords=[input_points],\n",
        "            point_labels=np.ones([input_points.shape[0], 1])\n",
        "        )\n",
        "        rle = masks_to_rle(masks[0])\n",
        "        file_name = result['img_id'].split('/')[-1]\n",
        "        predictions.append({\n",
        "            \"image_name\": file_name,\n",
        "            \"category_id\": \"0\",  # ID категории\n",
        "            \"bbox\": detection,  # Координаты bounding box\n",
        "            \"score\": scores[0],  # Оценка уверенности\n",
        "            \"segmentation\": {\n",
        "                \"size\" : rle[\"size\"],\n",
        "                \"counts\" : str(rle[\"counts\"])\n",
        "            }  # Сегментация в формате RLE\n",
        "        })"
      ],
      "metadata": {
        "id": "8PSwQz2pzfgq",
        "collapsed": true
      },
      "id": "8PSwQz2pzfgq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "output_folder = \"./\"\n",
        "# Сохранение предсказаний в JSON\n",
        "predictions_file = os.path.join(output_folder, \"submission.json\")\n",
        "with open(predictions_file, \"w\") as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "print(f\"Обработка завершена. Результаты сохранены в папке: {output_folder}\")"
      ],
      "metadata": {
        "id": "HO6J9jZLs3Jz"
      },
      "id": "HO6J9jZLs3Jz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch-wildlife",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}